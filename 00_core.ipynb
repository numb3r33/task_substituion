{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from task_substitution.external_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['_pct_missing_values', '_preprocess_categorical', '_ignore_flds', '_split_train_test', '_split_by_null']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Basic utility functions used across task substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _pct_missing_values(feature:pd.Series)->float:\n",
    "    \"\"\"\n",
    "    Given a feature calculates percentage of missing values\n",
    "    \"\"\"\n",
    "    if not isinstance(feature, pd.Series): feature = pd.Series(feature)\n",
    "    return feature.isnull().sum() / len(feature) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _pct_missing_values(pd.Series([1, np.nan, 2, 3])) == 25.0\n",
    "assert _pct_missing_values(pd.Series([1, 2, 3, 4])) == 0.0\n",
    "assert _pct_missing_values([1, 2, 3, 4]) == 0.0\n",
    "assert _pct_missing_values([1, np.nan, 3, 4]) == 25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _preprocess_categorical(cat_feat:pd.Series)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a categorical feature, label encode it.\n",
    "    \"\"\"\n",
    "    return pd.Categorical(cat_feat).codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame({'c': ['a', 'b', 'a']})\n",
    "\n",
    "assert type(_preprocess_categorical(example_df['c'])) == np.ndarray\n",
    "assert all(_preprocess_categorical(example_df['c']) == pd.Series([1, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _ignore_flds(df:pd.DataFrame, ignore_flds:list)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a dataframe and list of fields to ignore, this method would drop them from the dataframe\n",
    "    \"\"\"\n",
    "    df_cpy = df.copy()\n",
    "    df_cpy.drop(ignore_flds, axis=1, inplace=True)\n",
    "    return df_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame({'a': [1, 2, 3],\n",
    "                           'b': [3, 4, 1],\n",
    "                           'c': ['a', 'x', 'z']\n",
    "                          })\n",
    "\n",
    "assert type(_ignore_flds(example_df, ['a'])) == pd.DataFrame\n",
    "assert _ignore_flds(example_df, ['a']).shape[1] == 2\n",
    "assert _ignore_flds(example_df, ['a']).columns.tolist() == ['b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _split_by_null(df:pd.DataFrame, target_fld:str)->(pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Given a dataframe with target name it would split df into two dataframes\n",
    "    and shuffle both the dataframes as well, based on presence of value in the target feature or not.\n",
    "    \"\"\"\n",
    "    mask = df[target_fld].notnull()\n",
    "    train = df.loc[mask, :].sample(frac=1.)\n",
    "    test  = df.loc[~mask, :].sample(frac=1.)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_split_by_null\" class=\"doc_header\"><code>_split_by_null</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_split_by_null</code>(**`df`**:`DataFrame`, **`target_fld`**:`str`)\n",
       "\n",
       "Given a dataframe with target name it would split df into two dataframes\n",
       "and shuffle both the dataframes as well, based on presence of value in the target feature or not."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_split_by_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_fake_data_with_missing_values()\n",
    "\n",
    "train, test = _split_by_null(df, 'f3')\n",
    "assert len(test) == df.loc[df['f3'].isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _split_train_test(df:pd.DataFrame, split_params:dict)->(pd.DataFrame,pd.DataFrame):\n",
    "    train, test = train_test_split(df, **split_params)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_fake_numeric_data()\n",
    "\n",
    "train, test = _split_train_test(df, {'test_size': .2, 'random_state': 41})\n",
    "\n",
    "assert type(train) == pd.DataFrame\n",
    "assert type(test) == pd.DataFrame\n",
    "assert train.shape[1] == test.shape[1]\n",
    "assert len(test) == .2 * len(df)\n",
    "assert len(train) == .8 * len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_recover_missing.ipynb.\n",
      "Converted 04_external_data.ipynb.\n",
      "Converted 05_train_test_similarity.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "ts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
