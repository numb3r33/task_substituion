{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from task_substitution.data import *\n",
    "from task_substitution.model import *\n",
    "from task_substitution.external_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp recover_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner\n",
    "\n",
    "> Class that would take dataset and model args and recover missing values for a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecoverMissing:\n",
    "    \"\"\"Recover missing values for a feature using task substitution.\"\"\"\n",
    "    def __init__(self, target_fld:str, cat_flds:list=None, ignore_flds:list=None, perf_fn=None, split_args:dict=None, model_args:dict=None):\n",
    "        self.dataset_args = {'target_fld': target_fld,\n",
    "                             'cat_flds': cat_flds,\n",
    "                             'ignore_flds': ignore_flds\n",
    "                            }\n",
    "        \n",
    "        self.perf_fn = perf_fn\n",
    "        self.split_args = split_args\n",
    "        self.model_args = model_args\n",
    "        \n",
    "    def cv(self, X_train, y_train, X_test):\n",
    "        model = Model(**self.model_args)\n",
    "        fold_runs = model.cv(X_train, y_train, self.perf_fn)\n",
    "        \n",
    "        return fold_runs\n",
    "        \n",
    "    def recover(self, X_train, y_train, X_test):\n",
    "        model = Model(**self.model_args)\n",
    "        self.trained_model = model.fit(X_train, y_train)\n",
    "        recovered_values = self.trained_model.predict(X_test)\n",
    "        \n",
    "        return recovered_values\n",
    "        \n",
    "    def run(self, df):\n",
    "        df_cpy = df.copy()\n",
    "        \n",
    "        # create dataset class\n",
    "        data = Dataset(df_cpy, **self.dataset_args)\n",
    "        \n",
    "        # label encode categorical variables\n",
    "        df_cpy = data.preprocess()\n",
    "        \n",
    "        # store original index so that we can reindex the dataframe later\n",
    "        # to preserve the index of the original dataframe.\n",
    "        orig_index_order = df_cpy.index \n",
    "        \n",
    "        # split the dataset into train and test based on missing values in the\n",
    "        # feature which we want to recover\n",
    "        train, test = Dataset.split_train_test_by_null(df_cpy, self.dataset_args['target_fld'])\n",
    "        \n",
    "        \n",
    "        # further split train into tr and te\n",
    "        # do cross-validation on tr and report final performance\n",
    "        # on te\n",
    "        tr, te = Dataset.split_train_test(train, self.split_args)\n",
    "        \n",
    "        ytr = tr[self.dataset_args['target_fld']]\n",
    "        xtr = tr.drop(self.dataset_args['target_fld'], axis=1)\n",
    "        yte = te[self.dataset_args['target_fld']]\n",
    "        xte = te.drop(self.dataset_args['target_fld'], axis=1)\n",
    "        \n",
    "        fold_runs = self.cv(xtr, ytr, xte)\n",
    "        pred = self.recover(xtr, ytr, xte)\n",
    "        unseen_perf = self.perf_fn(yte, pred)\n",
    "        print(f'Performance on unseen dataset: {unseen_perf:.3f}')\n",
    "        \n",
    "        \n",
    "        # create target variable\n",
    "        y_train = train[self.dataset_args['target_fld']]\n",
    "        X_train = train.drop(self.dataset_args['target_fld'], axis=1)\n",
    "        \n",
    "        X_test = test.drop(self.dataset_args['target_fld'], axis=1)\n",
    "        \n",
    "        # train model to recover missing values\n",
    "        y_test = self.recover(X_train, y_train, X_test)\n",
    "        y_test = pd.Series(y_test, index=test.index)\n",
    "        \n",
    "        recovered_target = pd.concat([y_train, y_test]).reindex(orig_index_order)\n",
    "        df_cpy.loc[:, self.dataset_args['target_fld']] = recovered_target\n",
    "        \n",
    "        return df_cpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.170689</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.339072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.507860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  f2        f3\n",
       "0  0.170689   0  0.312148\n",
       "1  0.350181   0  0.210611\n",
       "2  0.339072   0  0.525557\n",
       "3  0.157173   0  0.673594\n",
       "4  0.507860   0  0.726123"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_fake_data_with_missing_values(); train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f3    0.02\n",
       "f2    0.00\n",
       "f1    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.isnull().sum() / len(train)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1    float64\n",
       "f2      int64\n",
       "f3    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score, mean_squared_error\n",
    "\n",
    "def run(train, params, num_boost_round):\n",
    "    \n",
    "    train_cpy = train.copy()\n",
    "    \n",
    "    y = train_cpy.f2\n",
    "    X = train_cpy.drop('f2', axis=1)\n",
    "    \n",
    "    kf = KFold(shuffle=True, random_state=41)\n",
    "    perfs = []\n",
    "    \n",
    "    for idx, (itr, ite) in enumerate(kf.split(X)):\n",
    "        Xtr, ytr = X.iloc[itr], y.iloc[itr]\n",
    "        Xval, yval = X.iloc[ite], y.iloc[ite]\n",
    "        \n",
    "        ltrain = lgb.Dataset(Xtr, ytr)\n",
    "        \n",
    "        model = lgb.train(params, ltrain, num_boost_round)\n",
    "        preds = model.predict(Xval)\n",
    "        \n",
    "        fold_perf = log_loss(yval, preds)\n",
    "        perfs.append(fold_perf)\n",
    "    \n",
    "    print(f'mean perf: {np.mean(perfs)}, std perf: {np.std(perfs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean perf: 0.8460135340844301, std perf: 0.015681166820867853\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'binary',\n",
    "          'learning_rate': 0.1,\n",
    "          'num_leaves': 31,\n",
    "          'min_data_in_leaf': 20\n",
    "         }\n",
    "\n",
    "num_boost_round = 100\n",
    "run(train, params, num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Performance: 0.2999708369544806\n",
      "Fold: 1\n",
      "Performance: 0.30431290980374\n",
      "Fold: 2\n",
      "Performance: 0.297611883751379\n",
      "Mean performance: 0.3006318768365332, Std performance: 0.0027753279485318826\n",
      "Performance on unseen dataset: 0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_args = {'objective': 'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'num_leaves': 31,\n",
    "          'min_data_in_leaf': 40,\n",
    "          'num_boost_round': 100,\n",
    "          'seed': 41\n",
    "         }\n",
    "\n",
    "split_args = {\n",
    "    'test_size': .2,\n",
    "    'random_state': 41\n",
    "}\n",
    "\n",
    "rec = RecoverMissing(target_fld='f3',\n",
    "                     cat_flds=[],\n",
    "                     ignore_flds=['f2'],\n",
    "                     perf_fn=lambda tr,pe: np.sqrt(mean_squared_error(tr, pe)),\n",
    "                     split_args=split_args,\n",
    "                     model_args=model_args\n",
    "                    )\n",
    "\n",
    "train_sub = rec.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.f3.isnull().sum(), train_sub.f3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean perf: 0.8402848595155269, std perf: 0.022482434047051185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'binary',\n",
    "          'learning_rate': 0.1,\n",
    "          'num_leaves': 31,\n",
    "          'min_data_in_leaf': 20\n",
    "         }\n",
    "\n",
    "num_boost_round = 100\n",
    "train_sub = train_sub.assign(f2=train.f2)\n",
    "run(train_sub, params, num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "ts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
